# iKOMA Agent Configuration Template
# Phase 1-B Unified Settings
# Copy this file to .env and customize as needed

# ===== LM Studio Configuration =====
# Unified port setting (11434) across all components
LMSTUDIO_BASE_URL=http://127.0.0.1:11434/v1
LMSTUDIO_MODEL=meta-llama-3-8b-instruct
LMSTUDIO_EMBED_MODEL=nomic-ai/nomic-embed-text-v1.5-GGUF

# ===== Vector Store Configuration =====
# Persistent Chromadb vector storage for semantic memory
VECTOR_STORE_PATH=agent/memory/vector_store
VECTOR_STORE_TYPE=chromadb
CHROMA_TELEMETRY=false

# ===== Agent Configuration =====
# Plan-execute-reflect system settings
MAX_ITERATIONS=3
MEMORY_LIMIT=1000
PLAN_TIMEOUT=30

# ===== File Operations Configuration =====
# Secure sandbox for file operations
SANDBOX_PATH=agent/ikoma_sandbox

# ===== Memory Configuration =====
# Dual memory system settings
MEMORY_SEARCH_LIMIT=5
MEMORY_SIMILARITY_THRESHOLD=0.7
CONVERSATION_DB_PATH=agent/memory/conversations.sqlite

# ===== Performance Configuration =====
# Optimization settings for Phase 1-B
ENABLE_TOOL_CACHING=true
ENABLE_SHARED_RESOURCES=true
STARTUP_TOOL_LOADING=true

# ===== Debug Configuration =====
# Development and debugging settings
DEBUG_MODE=false
LOG_LEVEL=INFO
VERBOSE_PLANNING=false
TRACE_EXECUTION=false

# ===== Security Configuration =====
# Safety and confirmation settings
REQUIRE_FILE_CONFIRMATION=true
SANDBOX_ISOLATION=true
USER_CONFIRMATION_TIMEOUT=30

# ===== Optional: OpenAI API Configuration =====
# For cloud models (if not using local LM Studio)
# OPENAI_API_KEY=your-key-here
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_EMBED_MODEL=text-embedding-3-small

# ===== Reflection System Configuration =====
# Nightly learning and analysis settings
REFLECTION_ENABLED=true
REFLECTION_HOUR=2
REFLECTION_STORAGE_LIMIT=100

# ===== Tool System Configuration =====
# Dynamic tool loading with MCP schema
TOOL_SCHEMA_PATH=tools/mcp_schema.json
TOOL_LOADING_STRATEGY=startup_only
TOOL_VALIDATION_ENABLED=true

# ===== Development Configuration =====
# Testing and development settings
TEST_MODE=false
MOCK_LLM_RESPONSES=false
OFFLINE_MODE=false 